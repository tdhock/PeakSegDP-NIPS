\documentclass[legalpaper]{article}
\usepackage{tikz}
%\usepackage{fullpage}
\usepackage{amsmath,amssymb}
\newcommand{\ZZ}{\mathbb Z}
\usepackage{color}
\newcommand{\NN}{\mathbb N}
\newcommand{\RR}{\mathbb R}
\DeclareMathOperator*{\minimize}{minimize}
\DeclareMathOperator*{\sign}{sign}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\Segments}{Segments}

\begin{document}

\section*{The Supervised Peak Detection Problem}

\begin{itemize}
\item A ChIP-seq profile on a single
chromosome with $d$ base pairs\\ is a vector $\mathbf y=
\left[
  \begin{array}{ccc}
    y_1 & \cdots & y_d
  \end{array}
\right]\in\ZZ_+^d$ of counts of aligned sequence reads. 
\item A peak caller is a function $c:\ZZ_+^d
  \rightarrow \{0, 1\}^d$\\
  which returns 0 for background noise and 1 for a peak.
\item We are given $i\in\{1,\dots, n\}$ profiles 
  $\mathbf y_i$ and annotated regions $R_i$.
\item The goal is to find a peak caller with minimal error on some
test profiles:
\begin{equation*}
  \label{eq:min_error}
  \minimize_c \sum_{i\in\text{test}} E[c(\mathbf y_i),  R_i],
\end{equation*}
where $E$ is the number of false positive and false negative regions $R_i$.
\end{itemize}

\newpage 

\section*{Unsupervised PeakSeg: 
constrained segmentation}

\begin{equation*}
  \label{argmin:constrained}
  \begin{aligned}
    \mathbf{\tilde m}^s(\mathbf y)  =\ 
    &\argmin_{\mathbf m\in\RR^{d}} && 
    %\sum_{j=1}^d \log\Lik
    \rho
    (\mathbf m, \mathbf y) \\
    \\
    &\text{such that} && \Segments(\mathbf m)=s,\\
    \textbf{Peaks constraint:}
    & && P_j(\mathbf m) \in\{0, 1\} \text{ for all } j\in\{1, \dots, d\}.
  \end{aligned}
\end{equation*}
\begin{itemize}
\item The Poisson loss function is $\rho(\mathbf m, \mathbf y)=
  \sum_{j=1}^d m_j - y_j \log m_j$.
\item$\Segments(\mathbf m)\in\{1, \dots, d\}$ is the number of
  piecewise constant segments of the mean vector $\mathbf m$.
\item The indicator for a peak at base $j$ is 
$
  P_j(\mathbf m) = \sum_{k=1}^j \sign( m_k - m_{k-1} ).
$
\item Geometric interpretation of \textbf{Peaks constraint}:\\
  segment mean must change up, down, up, down, ...
\item For example for $s=5$ segments, mean values should satisfy\\
  $\mu_1 < \mu_2 > \mu_3 < \mu_4 > \mu_5$.
\end{itemize}

\newpage

\section*{Supervised PeakSeg: learning a penalty function}
Reference: Hocking, Rigaill, et al. Learning Sparse Penalties for
Change-point Detection using Max Margin Interval Regression. ICML
2013.

\begin{itemize}
\item Given a positive penalty $\lambda\in\RR_+$, the optimal number
  of segments is
\begin{equation*} s^*(\lambda, \mathbf y) =
    \argmin_{s\in\{1,3,\dots, s_{\text{max}}\}} \rho\left[
      \mathbf{\tilde m}^s(\mathbf y), \mathbf y \right] + \lambda s.
\end{equation*}
\item Sample-specific penalty values $\log \lambda_i = 
\textcolor{blue}{
  f(\mathbf x_i)
  = \beta + \mathbf w^\intercal \mathbf x_i
}$.
\item An $m=2$-dimensional feature vector
$\mathbf x_i = \left[\begin{array}{cc} \log\max \mathbf y_i & \log d_i
\end{array}\right]$,\\ where $d_i$ is the number of base pairs for 
sample $i$.
\item \textbf{Geometric interpretation: interval regression.} \\
  the minimum error
  \textcolor{blue}{penalty function $f$} \\
  intersects the target
  interval of penalty values for each sample.
\item For separable data, find the 
  \textcolor{blue}{penalty function $f$} 
with
\textcolor{red}{largest margin}:\\
\input{figure-interval-regression}
\end{itemize}

\newpage

For real data: minimize a smooth convex squared hinge loss
$\ell_i:\RR\rightarrow\RR_+$ which depends on the annotated region
data $R_i$:
\begin{equation*}
  \label{eq:relax}
  \hat f = \argmin_f \sum_{i=1}^n
  \ell_i\left[ f(\mathbf x_i) \right].
\end{equation*}
To make a prediction on a
test sample with profile $\mathbf y$ and features $\mathbf x$,
\begin{itemize}
\item Compute the predicted penalty $\hat \lambda = \exp \hat f(\mathbf x)$,
\item the predicted number of segments $\hat s = s^*(\hat \lambda, \mathbf
y)$, 
\item and finally the predicted peaks $\mathbf P\left[ \mathbf{\tilde
    m}^{\hat s}(\mathbf y) \right]$,\\
where $\mathbf P[\mathbf m] = \left[\begin{array}{ccc}
    P_1(\mathbf m) & \cdots & P_d(\mathbf m)
\end{array}\right]\in\{0, 1\}^d$.
\end{itemize}

\end{document}
